B_hat <- matrix(0, nrow = n, ncol = components)
for(i in 1:n) {
ll <- c()
for(k in 1:components){
ll[k] <- sum(responsibilities[i,k])
}
B_hat[i, which.max(ll)] <- 1
x_hat[i,] <- B_hat[i,]*x[i]
}
colnames(B_hat) <- paste0("B", 1:components)
colnames(x_hat) <- paste0("x", 1:components)
B_hat <- dplyr::as_tibble(B_hat)
x_hat <- dplyr::as_tibble(x_hat)
z_hat <- dplyr::as_tibble((x_hat-params$mean)/params$sd*B_hat)
colnames(z_hat) <- paste0("z", 1:components)
df_fitted <- dplyr::bind_cols(B_hat, x_hat, z_hat)
# Assign a name to the parameters
names(params$mean) <- paste0("mu", 1:components)
names(params$sd) <- paste0("sd", 1:components)
names(params$p) <- paste0("p", 1:components)
# Parameters on fitted sub-samples
params_hat <- params
for(k in 1:components){
component_name <- paste0("x", k)
component <- df_fitted[w == 1,]
component <- component[component[, component_name] != 0,]
params_hat$mean[k] <- mean(component[[component_name]], na.rm = na.rm)
params_hat$sd[k] <- sd(component[[component_name]], na.rm = na.rm)
params_hat$p[k] <- mean(df_fitted[[paste0("B", k)]], na.rm = na.rm)
}
# Reorder the components by decreasing means
idx_order <- order(params$mean)
params$mean <- params$mean[idx_order]
params$sd <- params$sd[idx_order]
params$p <- params$p[idx_order]
params_hat$mean <- params_hat$mean[idx_order]
params_hat$sd <- params_hat$sd[idx_order]
params_hat$p <- params_hat$p[idx_order]
colnames(responsibilities) <- paste0("B", 1:components)
responsibilities <- dplyr::as_tibble(responsibilities)
# Log-likelihood on fitted parameters
# Calculate the log-likelihood
log_likelihood <- 0
for(i in 1:n) {
ll <- 0
for(k in 1:components){
ll <- ll + params_hat$p[k]*dnorm(x[i], params_hat$mean[k], params_hat$sd[k])
}
log_likelihood <- sum(c(log_likelihood, log(ll)*w[i]), na.rm = TRUE)
}
structure(
list(
iteration = iteration,
par = params,
par_hat = params_hat,
responsibilities = responsibilities,
log_lik = previous_log_likelihood,
log_lik_hat = log_likelihood,
fitted = df_fitted
),
class = c("gaussianMixture")
)
}
gaussianMixture(x$X, means, sd, p, components = 3, maxit = 0)$par
gaussianMixture <- function(x, means, sd, p, components = 2, weights, maxit = 100, abstol = 10e-15,  na.rm = FALSE){
require(mclust)
# Number of observations
n <- length(x)
# Custom weights
if (missing(weights)) {
w <- rep(1, n)
} else {
w <- ifelse(weights == 0, 0, 1)
}
# Empirical moments
e_x_hat <- mean(x[w != 0], na.rm = na.rm)
v_x_hat <- var(x[w != 0], na.rm = na.rm)
sd_x_hat <- sqrt(v_x_hat)
# Update number of observation
n_w <- length(x[w != 0])
# Initial parameters
clust <- mclust::Mclust(x[w!=0], G = components, verbose = FALSE)
# Default means
if (missing(means) || any(is.na(means))){
# means <- quantile(x, probs = seq(0.2, 0.8, length.out = components))
means <- clust$parameters$mean
}
# Default std. deviations
if (missing(sd) || any(is.na(sd))){
# sd <- rep(sd_x_hat, components)
sd <- clus$parameters$variance$scale
}
# Default probabilities
if (missing(p) || any(is.na(p))) {
# p <- rep(1/components, components)
p <- clus$parameters$pro
}
# Rescale probabilities
p <- p/sum(p)
# 0. Initialization
# Routine
if (maxit == 0) {
# E-step: posterior probabilities
params <- list(mean = means, sd = sd, p = p)
responsibilities <- matrix(0, nrow = n, ncol = components)
for (i in 1:n) {
for(k in 1:components){
responsibilities[i, k] <- params$p[k]*dnorm(x[i], params$mean[k], params$sd[k])
}
# Normalize the posterior probabilities
responsibilities[i,][is.na(responsibilities[i,])] <- 0
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
responsibilities[i,] <- (responsibilities[i,])/sum(responsibilities[i,])
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
}
# Calculate the log-likelihood
log_likelihood <- 0
for(i in 1:n) {
ll <- 0
for(k in 1:components){
ll <- ll + params$p[k]*dnorm(x[i], params$mean[k], params$sd[k])
}
log_likelihood <- sum(c(log_likelihood, log(ll)*w[i]), na.rm = TRUE)
}
# Update log-likelihood
previous_log_likelihood <- log_likelihood
iteration <- 0
} else {
# 0. Initialization
log_likelihood <- 0
previous_log_likelihood <- -Inf
prev_responsibilities <- matrix(0, nrow = n, ncol = components)
previous_params <- list(mean = means, sd = sd, p = p)
# EM Algorithm
for (iteration in 1:maxit) {
# E-step: posterior probabilities
responsibilities <- prev_responsibilities
for (i in 1:n) {
for(k in 1:components){
responsibilities[i, k] <- previous_params$p[k]*dnorm(x[i], previous_params$mean[k], previous_params$sd[k])
}
# Normalize the posterior probabilities
responsibilities[i,][is.na(responsibilities[i,])] <- 0
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
responsibilities[i,] <- (responsibilities[i,])/sum(responsibilities[i,])
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
}
# Optimal parameters
params <- previous_params
# M-step: Update the parameters
for(k in 1:components){
# Normalizing factor for each group
n_k <- sum(w*responsibilities[, k], na.rm = na.rm)
# Mean parameter k-component
params$mean[k] <- sum(responsibilities[, k]*w*x, na.rm = na.rm)/n_k
# Std. deviation k-component
params$sd[k] <- sqrt(sum(responsibilities[, k]*w*(x - params$mean[k])^2, na.rm = na.rm)/n_k)
# Probability k-component
params$p[k] <- n_k/n_w
}
if (any(params$p > 0.9)) {
responsibilities <- prev_responsibilities
params <- previous_params
break
}
# Calculate the log-likelihood
log_likelihood <- 0
for(i in 1:n) {
ll <- 0
for(k in 1:components){
ll <- ll + params$p[k]*dnorm(x[i], params$mean[k], params$sd[k])
}
log_likelihood <- sum(c(log_likelihood, log(ll)*w[i]), na.rm = TRUE)
}
# Check for convergence
stop_condition <- abs(log_likelihood - previous_log_likelihood) < abstol
if (stop_condition) {
break
} else {
# Update log-likelihood
previous_log_likelihood <- log_likelihood
}
}
}
# Final classification of each component
x_hat <- matrix(0, nrow = n, ncol = components)
B_hat <- matrix(0, nrow = n, ncol = components)
for(i in 1:n) {
ll <- c()
for(k in 1:components){
ll[k] <- sum(responsibilities[i,k])
}
B_hat[i, which.max(ll)] <- 1
x_hat[i,] <- B_hat[i,]*x[i]
}
colnames(B_hat) <- paste0("B", 1:components)
colnames(x_hat) <- paste0("x", 1:components)
B_hat <- dplyr::as_tibble(B_hat)
x_hat <- dplyr::as_tibble(x_hat)
z_hat <- dplyr::as_tibble((x_hat-params$mean)/params$sd*B_hat)
colnames(z_hat) <- paste0("z", 1:components)
df_fitted <- dplyr::bind_cols(B_hat, x_hat, z_hat)
# Assign a name to the parameters
names(params$mean) <- paste0("mu", 1:components)
names(params$sd) <- paste0("sd", 1:components)
names(params$p) <- paste0("p", 1:components)
# Parameters on fitted sub-samples
params_hat <- params
for(k in 1:components){
component_name <- paste0("x", k)
component <- df_fitted[w == 1,]
component <- component[component[, component_name] != 0,]
params_hat$mean[k] <- mean(component[[component_name]], na.rm = na.rm)
params_hat$sd[k] <- sd(component[[component_name]], na.rm = na.rm)
params_hat$p[k] <- mean(df_fitted[[paste0("B", k)]], na.rm = na.rm)
}
# Reorder the components by decreasing means
idx_order <- order(params$mean)
params$mean <- params$mean[idx_order]
params$sd <- params$sd[idx_order]
params$p <- params$p[idx_order]
params_hat$mean <- params_hat$mean[idx_order]
params_hat$sd <- params_hat$sd[idx_order]
params_hat$p <- params_hat$p[idx_order]
colnames(responsibilities) <- paste0("B", 1:components)
responsibilities <- dplyr::as_tibble(responsibilities)
# Log-likelihood on fitted parameters
# Calculate the log-likelihood
log_likelihood <- 0
for(i in 1:n) {
ll <- 0
for(k in 1:components){
ll <- ll + params_hat$p[k]*dnorm(x[i], params_hat$mean[k], params_hat$sd[k])
}
log_likelihood <- sum(c(log_likelihood, log(ll)*w[i]), na.rm = TRUE)
}
structure(
list(
iteration = iteration,
par = params,
par_hat = params_hat,
responsibilities = responsibilities,
log_lik = previous_log_likelihood,
log_lik_hat = log_likelihood,
fitted = df_fitted
),
class = c("gaussianMixture")
)
}
gaussianMixture(x$X, means, sd, p, components = 3, maxit = 0)$par
gaussianMixture(x$X, components = 3, maxit = 0)$par
gaussianMixture <- function(x, means, sd, p, components = 2, weights, maxit = 100, abstol = 10e-15,  na.rm = FALSE){
require(mclust)
# Number of observations
n <- length(x)
# Custom weights
if (missing(weights)) {
w <- rep(1, n)
} else {
w <- ifelse(weights == 0, 0, 1)
}
# Empirical moments
e_x_hat <- mean(x[w != 0], na.rm = na.rm)
v_x_hat <- var(x[w != 0], na.rm = na.rm)
sd_x_hat <- sqrt(v_x_hat)
# Update number of observation
n_w <- length(x[w != 0])
# Initial parameters
clust <- mclust::Mclust(x[w!=0], G = components, verbose = FALSE)
# Default means
if (missing(means) || any(is.na(means))){
# means <- quantile(x, probs = seq(0.2, 0.8, length.out = components))
means <- clust$parameters$mean
}
# Default std. deviations
if (missing(sd) || any(is.na(sd))){
# sd <- rep(sd_x_hat, components)
sd <- clust$parameters$variance$scale
}
# Default probabilities
if (missing(p) || any(is.na(p))) {
# p <- rep(1/components, components)
p <- clust$parameters$pro
}
# Rescale probabilities
p <- p/sum(p)
# 0. Initialization
# Routine
if (maxit == 0) {
# E-step: posterior probabilities
params <- list(mean = means, sd = sd, p = p)
responsibilities <- matrix(0, nrow = n, ncol = components)
for (i in 1:n) {
for(k in 1:components){
responsibilities[i, k] <- params$p[k]*dnorm(x[i], params$mean[k], params$sd[k])
}
# Normalize the posterior probabilities
responsibilities[i,][is.na(responsibilities[i,])] <- 0
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
responsibilities[i,] <- (responsibilities[i,])/sum(responsibilities[i,])
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
}
# Calculate the log-likelihood
log_likelihood <- 0
for(i in 1:n) {
ll <- 0
for(k in 1:components){
ll <- ll + params$p[k]*dnorm(x[i], params$mean[k], params$sd[k])
}
log_likelihood <- sum(c(log_likelihood, log(ll)*w[i]), na.rm = TRUE)
}
# Update log-likelihood
previous_log_likelihood <- log_likelihood
iteration <- 0
} else {
# 0. Initialization
log_likelihood <- 0
previous_log_likelihood <- -Inf
prev_responsibilities <- matrix(0, nrow = n, ncol = components)
previous_params <- list(mean = means, sd = sd, p = p)
# EM Algorithm
for (iteration in 1:maxit) {
# E-step: posterior probabilities
responsibilities <- prev_responsibilities
for (i in 1:n) {
for(k in 1:components){
responsibilities[i, k] <- previous_params$p[k]*dnorm(x[i], previous_params$mean[k], previous_params$sd[k])
}
# Normalize the posterior probabilities
responsibilities[i,][is.na(responsibilities[i,])] <- 0
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
responsibilities[i,] <- (responsibilities[i,])/sum(responsibilities[i,])
responsibilities[i,][is.nan(responsibilities[i,])] <- 0
}
# Optimal parameters
params <- previous_params
# M-step: Update the parameters
for(k in 1:components){
# Normalizing factor for each group
n_k <- sum(w*responsibilities[, k], na.rm = na.rm)
# Mean parameter k-component
params$mean[k] <- sum(responsibilities[, k]*w*x, na.rm = na.rm)/n_k
# Std. deviation k-component
params$sd[k] <- sqrt(sum(responsibilities[, k]*w*(x - params$mean[k])^2, na.rm = na.rm)/n_k)
# Probability k-component
params$p[k] <- n_k/n_w
}
if (any(params$p > 0.9)) {
responsibilities <- prev_responsibilities
params <- previous_params
break
}
# Calculate the log-likelihood
log_likelihood <- 0
for(i in 1:n) {
ll <- 0
for(k in 1:components){
ll <- ll + params$p[k]*dnorm(x[i], params$mean[k], params$sd[k])
}
log_likelihood <- sum(c(log_likelihood, log(ll)*w[i]), na.rm = TRUE)
}
# Check for convergence
stop_condition <- abs(log_likelihood - previous_log_likelihood) < abstol
if (stop_condition) {
break
} else {
# Update log-likelihood
previous_log_likelihood <- log_likelihood
}
}
}
# Final classification of each component
x_hat <- matrix(0, nrow = n, ncol = components)
B_hat <- matrix(0, nrow = n, ncol = components)
for(i in 1:n) {
ll <- c()
for(k in 1:components){
ll[k] <- sum(responsibilities[i,k])
}
B_hat[i, which.max(ll)] <- 1
x_hat[i,] <- B_hat[i,]*x[i]
}
colnames(B_hat) <- paste0("B", 1:components)
colnames(x_hat) <- paste0("x", 1:components)
B_hat <- dplyr::as_tibble(B_hat)
x_hat <- dplyr::as_tibble(x_hat)
z_hat <- dplyr::as_tibble((x_hat-params$mean)/params$sd*B_hat)
colnames(z_hat) <- paste0("z", 1:components)
df_fitted <- dplyr::bind_cols(B_hat, x_hat, z_hat)
# Assign a name to the parameters
names(params$mean) <- paste0("mu", 1:components)
names(params$sd) <- paste0("sd", 1:components)
names(params$p) <- paste0("p", 1:components)
# Parameters on fitted sub-samples
params_hat <- params
for(k in 1:components){
component_name <- paste0("x", k)
component <- df_fitted[w == 1,]
component <- component[component[, component_name] != 0,]
params_hat$mean[k] <- mean(component[[component_name]], na.rm = na.rm)
params_hat$sd[k] <- sd(component[[component_name]], na.rm = na.rm)
params_hat$p[k] <- mean(df_fitted[[paste0("B", k)]], na.rm = na.rm)
}
# Reorder the components by decreasing means
idx_order <- order(params$mean)
params$mean <- params$mean[idx_order]
params$sd <- params$sd[idx_order]
params$p <- params$p[idx_order]
params_hat$mean <- params_hat$mean[idx_order]
params_hat$sd <- params_hat$sd[idx_order]
params_hat$p <- params_hat$p[idx_order]
colnames(responsibilities) <- paste0("B", 1:components)
responsibilities <- dplyr::as_tibble(responsibilities)
# Log-likelihood on fitted parameters
# Calculate the log-likelihood
log_likelihood <- 0
for(i in 1:n) {
ll <- 0
for(k in 1:components){
ll <- ll + params_hat$p[k]*dnorm(x[i], params_hat$mean[k], params_hat$sd[k])
}
log_likelihood <- sum(c(log_likelihood, log(ll)*w[i]), na.rm = TRUE)
}
structure(
list(
iteration = iteration,
par = params,
par_hat = params_hat,
responsibilities = responsibilities,
log_lik = previous_log_likelihood,
log_lik_hat = log_likelihood,
fitted = df_fitted
),
class = c("gaussianMixture")
)
}
gaussianMixture(x$X, components = 3, maxit = 0)$par
gaussianMixture(x$X, components = 3, maxit = 0)$par
x <- x$X
components = 2
weights
maxit = 100
abstol = 10e-15
na.rm = FALSE
# Number of observations
n <- length(x)
# Custom weights
if (missing(weights)) {
w <- rep(1, n)
} else {
w <- ifelse(weights == 0, 0, 1)
}
w <- rep(1, n)
# Initialize the parameters
clust <- mclust::Mclust(x[w!=0], G = components, verbose = FALSE)
# means <- quantile(x, probs = seq(0.2, 0.8, length.out = components))
means <- clust$parameters$mean
# sd <- rep(sd_x_hat, components)
sd <- clust$parameters$variance$scale
# p <- rep(1/components, components)
p <- clust$parameters$pro
# Rescale probabilities
p <- p/sum(p)
mixture_responsabilities <- function(x, params, components) {
responsibilities <- matrix(0, nrow = n, ncol = components)
for(k in 1:components){
responsibilities[, k] <- params$p[k]*dnorm(x, params$mean[k], params$sd[k])
}
responsibilities
}
mixture_responsabilities(x, params, components)
mixture_responsabilities(x, previous_params, components)
previous_params <- list(mean = means, sd = sd, p = p)
mixture_responsabilities(x, previous_params, components)
responsibilities <- mixture_responsabilities(x, previous_params, components)
# Normalize the posterior probabilities
responsibilities[is.na(responsibilities),]
# Normalize the posterior probabilities
responsibilities[is.na(responsibilities)]
# Normalize the posterior probabilities
responsibilities
# Normalize the posterior probabilities
rowSums(responsibilities)
# Normalize the posterior probabilities
responsibilities/rowSums(responsibilities)
# Normalize the posterior probabilities
responsibilities <- responsibilities/rowSums(responsibilities)
rowSums(responsibilities)
sapply(responsibilities, is.na)
apply(responsibilities, 2, is.na)
apply(responsibilities, 2, ~function(x) ifelse(is.na(x), 0, x))
apply(responsibilities, 2, ~function(x) ifelse(is.na(x), 0, x))
apply(responsibilities, 2, ~is.na(x))
apply(responsibilities, 2, is.na(x))
apply(responsibilities, 2, function(x) ifelse(is.na(x), 0, x))
responsibilities[4,] <- NA
apply(responsibilities, 2, function(x) ifelse(is.na(x), 0, x))
responsibilities[4,]
apply(responsibilities, 2, function(x) ifelse(is.na(x), 0, x))[4,]
mixture_responsabilities <- function(x, params, components) {
responsibilities <- matrix(0, nrow = n, ncol = components)
for(k in 1:components){
responsibilities[, k] <- params$p[k]*dnorm(x, params$mean[k], params$sd[k])
}
# Normalize the posterior probabilities
responsibilities <- apply(responsibilities, 2, function(x) ifelse(is.na(x), 0, x))
responsibilities <- apply(responsibilities, 2, function(x) ifelse(is.nan(x), 0, x))
responsibilities <- responsibilities/rowSums(responsibilities)
responsibilities
}
responsibilities <- mixture_responsabilities(x, previous_params, components)
responsibilities
